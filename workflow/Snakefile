import os, glob, sys
import subprocess as sp
from itertools import groupby

configfile: "../config/config.json"

# Get custom parameters
input_fasta = config.get("input_fasta")  # path
step_size = config.get("step_size")  # int
chunks = config.get("chunks")  # True or None
chunk_size = config.get("chunk_size")  # int or None
strand = config.get("strand")  # 'both', '+' or '-'
batch_size = config.get('batch_size')
output_name_ = config.get('output_name')
ext = config.get("output_type")
profile = config.get("profile")
dryrun = config.get("dryrun")
gpu = config.get("gpu_generation")


include: "rules/common.smk"
include: "rules/download.smk"

if not config.get("download_model"):
    if config.get("input_bed") == None:
        if chunks == True:
            CHR_, CHR_sizes = get_chr_names(input_fasta, chunks, chunk_size, 
                                dryrun=dryrun, gpu=gpu)
        else:
            CHR_dict = get_chr_names(input_fasta, chunks, chunk_size, 
                                dryrun=dryrun, gpu=gpu)
            CHR_ = list(CHR_dict.keys())
            CHR_sizes = list(CHR_dict.values())

        CHR_ = [c.replace(' ', '') for c in CHR_]
        config['CHR_'] = CHR_
        config['CHR_sizes'] = {c : CHR_sizes[i] for i, c in enumerate(CHR_)}
    if (config.get("input_bed") != None) & (config.get("dryrun") == None):
        # Find if entries have a specified strand (if not, it doubles the 
        # number of predictions as we will predict on both strand)
        input_bed_path = config.get('input_bed')
        strand_cmd = """awk -v OFS='\t' '$6 !="+" && $6 !="-"' """+ \ 
                    input_bed_path + """ | wc -l"""
        no_strand = sp.run([strand_cmd], shell=True, 
                    capture_output=True, text=True).stdout.strip()
        len_bed = sp.run(["cat "+input_bed_path+" | wc -l"], shell=True, 
                    capture_output=True, text=True).stdout.strip()

        # total_entries includes double prediction for entries with no strand 
        # specified (thus prediction on both + and - strand)
        total_entries = int(no_strand) + int(len_bed)
        config['bed_entries'] = total_entries

    rule all:
        """ Run SnoBIRD to predict C/D box snoRNA genes in a genomic sequence."""
        input:
            final_output = expand('results/final/{output_name}.{output_type}', 
                                    output_type=ext, output_name=output_name_)

rule all_downloads:
    """ Download all models that constitute SnoBIRD and create the virtualenv 
        in which SnoBIRD will be run."""
    input:
        model1 = "data/references/models/snoBIRD_first_model.pt",
        model2 = "data/references/models/snoBIRD_second_model.pt",
        tokenizer = "data/references/DNA_BERT_6_tokenizer/",
        dnabert = "data/references/DNA_BERT_6_pretrained_model/",
        env = "envs/snoBIRD_env.tar.gz"



include: "rules/snoBIRD.smk"
#include: "rules/target_prediction.smk"

# Define which rule to run depending if only SnoBIRD's first model 
# is run or if both models are run 
if config.get("first_model_only") == True:
    ruleorder: find_sno_limits_shap_minimal > filter_sno_pseudo_predictions_with_features
else:
    ruleorder: filter_sno_pseudo_predictions_with_features > find_sno_limits_shap_minimal

# Define which rule to run depending if an input bed file was provided
if config.get("input_bed") != None:
    ruleorder: predict_and_filter_bed_windows > merge_filter_windows
else:
    ruleorder: merge_filter_windows > predict_and_filter_bed_windows
